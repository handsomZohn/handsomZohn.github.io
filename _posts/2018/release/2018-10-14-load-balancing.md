---
layout: post
title: 应用服务器集群的伸缩设计
category: other
tags: [other]
no-post-nav: true
excerpt: 负载均衡是网站必不可少的基础技术手段，不但可以实现网站的伸缩性，同时还改善网站的性能。
keywords: 原创
---

##Http重定向负载均衡

**流程：**
 
	  用户通过浏览器发起访问请求（130.10.7.143）-->
      请求到达Http重定向负载均衡服务器（130.10.7.255）-->
	  Http重定向负载均衡服务器响应（浏览器）重定向至Web服务器集群中的某一台服务（130.10.7.100）-->
	  浏览器自动重新请求Web服务器集群中的某一台服务器（130.10.7.100）
**优缺点：**

	优点：比较简单
	缺点：两次请求服务器完成一次访问，性能较差；
		 重定向服务器自身的处理能力会成为瓶颈，整个集群的伸缩性规模有限；
		 使用Http302响应码重定向，有可能使搜索引擎判断为SEO作弊，降低搜索排名。


---

##DNS域名解析负载均衡
**流程：**

	浏览器请求域名服务器解析域名（www.handsomzohn.xyz）-->
	请求到达域名服务器-->
    域名服务器返回IP地址（130.10.8.2）给用户浏览器-->
    浏览器请求130.10.8.2，访问真实物理机

**优缺点：**

	优点：负载均衡的工作转交DNS，省掉网站管理维护负载均衡服务器的麻烦，同时DNS支持地理位置
		 的域名解析，加快访问速度，改善性能
	缺点：DNS多级解析，每一级的DNS都有可能缓存A记录，某台服务器下线，即使修改DNS的A记录，
		 使其生效也需要较长一段时间，这段时间DNS依旧会把域名解析到已经下线的服务器，导致用户访问失败；
		 DNS负载均衡的控制权在域名服务商那里部分使用DNS域名解析，第一部分利用域名解析作为第一级负载均衡手段，
		 域名解析得到的不是实际提供Web服务的服务器，而是同样提供负载均衡服务的内部服务器，在这组内部负载均衡服务器再进行负载均衡，将请求分发到真实的Web服务器上；

##反向代理负载均衡

**流程：**

	浏览器（130.10.7.143）请求反向代理服务器-->
	反向代理服务器（130.10.7.255）收到请求后，根据负载均衡算法得到一台真实服务器的地址10.0.0.3-->
    反向代理服务器（130.10.7.255）将收到的请求转发到10.0.0.3-->
    物理服务器接收请求并处理，将响应返回反向代理服务器（130.10.7.255）-->
    反向代理服务器（130.10.7.255）接收物理服务器（10.0.0.3）的响应，返回给浏览器（130.10.7.134）

**优缺点**

	优点：和反向代理服务器集成在一起，部署简单；
	缺点：反向代理服务器是所有请求和响应的中转站，其性能可能会称为瓶颈


##IP负载均衡(网络层通过修改请求目标地址进行负载均衡)

**流程：**

	浏览器（200.10.10.1）请求到达负载均衡服务器（114.100.80.10）-->
    负载均衡服务器在操作系统获取网络数据包，根据负载均衡算法得到一台真是Web服务器（10.0.0.1）-->
    将数据包目的IP修改为10.0.0.1[不需要用户进行处理],并进行请求-->
    真实Web服务器处理完之后，响应数据包回到负载均衡服务器-->
    负载均衡服务器再将数据包源地址修改为自身的IP地址（114.100.800.10）发送给浏览器

**优缺点**

	优点：在内核进程完成数据的分发，较反向代理负载均衡（在应用程序中分发数据）有更好的性能；
	缺点：所有请求响应都需要经过负载均衡服务器，集群的最大响应数据吞吐量不得不受制于负载均衡服务器网卡带宽；
	考虑：负载均衡服务器只分发请求，响应数据从真实物理服务器直接返回给用户

##数据链路层负载均衡（三角传输模式、直接路由方式）

**流程：**

	浏览器（200.10.10.1）请求到达负载均衡服务器（114.100.80.10）-->
    负载均衡服务器将请求数据的目的mac地址修改为00:0c:29:d2,并不修改时数据包IP地址-->
    Web服务器集群所有服务器的虚拟IP都和负载均衡服务器的IP地址相同，数据可以到达mac地址为00:0c:29:d2对应的服务器
    服务器处理完后发送响应数据到网站的网管服务器-->
    网管服务器直接将该数据包发送到用户浏览器（通过互联网）

**优缺点**

	优点：使用最为广泛；


##负载均衡算法
负载均衡服务器的实现：
1. 根据负载均衡算法和Web服务器列表计算得到集群中一台Web服务器的地址；
2. 将请求数据发送到该地址对应的Web服务器。

轮询（Round Robin，RR）

	所有请求一次分发到每台应用服务器，每台应用服务器处理的请求数目相同，适合服务器硬件全部相同的场景；

加权轮询（Weighted Round Robin， WRR）

	在轮询的基础上，根据应用服务器硬件性能情况，按照配置的权重将请求分发到每个服务器，高性能的服务器分配更多的请求。

随机（Random）

	请求被随机分配到各个服务器，好的随机数本身就很均衡。
最少连接（Least Connections）

	记录每个应用服务器正在处理的连接数，将新到的请求分配到最少连接的服务器上；
源地址散列（Source Hashing）

	根据请求来源的IP地址进行Hash计算，得到应用服务器，这样将来自同一个IP地址的请求总在同一个服务器上处理，该请求的上下文信息可以存储在这台服务器上，在一个会话周期内重复使用从而实现会话粘滞；